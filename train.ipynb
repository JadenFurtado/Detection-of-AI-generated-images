{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.patch_generator import smash_n_reconstruct\n",
    "import preprocessing.filters as f\n",
    "import tensorflow as tf\n",
    "from keras import layers,Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def hard_tanh(x):\n",
    "    return tf.maximum(tf.minimum(x, 1), -1)\n",
    "\n",
    "class featureExtractionLayer(layers.Layer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.conv = layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.activation = layers.Lambda(hard_tanh)\n",
    "        \n",
    "    def call(self, input):\n",
    "        x = self.conv(input)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = layers.Input(shape=(256,256,1),name=\"rich_texture\")\n",
    "input2 = layers.Input(shape=(256,256,1),name=\"poor_texture\")\n",
    "\n",
    "l1 = featureExtractionLayer(name=\"feature_extraction_layer_rich_texture\")(input1)\n",
    "l2 = featureExtractionLayer(name=\"feature_extraction_layer_poor_texture\")(input2)\n",
    "\n",
    "contrast = layers.subtract((l1,l2))\n",
    "\n",
    "x = layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu')(contrast)\n",
    "x = layers.BatchNormalization()(x)\n",
    "for i in range(3):\n",
    "    x = layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "for i in range(4):\n",
    "    x = layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "x = layers.AveragePooling2D()(x)\n",
    "\n",
    "for i in range(2):\n",
    "    x = layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "x = layers.AveragePooling2D()(x)\n",
    "\n",
    "for i in range(2):\n",
    "    x = layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=(input1,input2), outputs=x, name=\"rich_texture_poor_texture_contrast\")\n",
    "model.compile(\n",
    "                optimizer='adam',\n",
    "                loss='BinaryCrossentropy',\n",
    "                metrics='binary_accuracy'\n",
    "            )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ai = './test_imgs/dataset/fakeV2/fake-v2/'\n",
    "ai_imgs = [os.path.join(path_ai,img) for img in os.listdir(path_ai)]\n",
    "ai_label = [1 for i in range(len(ai_imgs))]\n",
    "path_real = './test_imgs/dataset/real/'\n",
    "real_imgs = [os.path.join(path_real,img) for img in os.listdir(path_real)]\n",
    "real_label = [0 for i in range(len(real_imgs))]\n",
    "print(len(real_imgs),len(ai_imgs))\n",
    "X_train = ai_imgs[:-21] + real_imgs[:-21]\n",
    "y_train = ai_label[:-21] + real_label[:-21]\n",
    "X_validate = ai_imgs[-21:] + real_imgs[-21:]\n",
    "y_validate = ai_label[-21:] + real_label[-21:]\n",
    "len(X_train),len(y_train),len(X_validate),len(y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path,label:int):\n",
    "    rt,pt = smash_n_reconstruct(path.numpy().decode('utf-8'))\n",
    "    frt = tf.cast(tf.expand_dims(f.apply_all_filters(rt),axis=-1),dtype=tf.float64)\n",
    "    fpt = tf.cast(tf.expand_dims(f.apply_all_filters(pt), axis=-1),dtype=tf.float64)\n",
    "    return frt,fpt,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_map(X1,X2,y):\n",
    "    return {\n",
    "        'rich_texture':X1,\n",
    "        'poor_texture':X2\n",
    "    },y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataset = (tf.data.Dataset.from_tensor_slices((X_train,y_train))\n",
    "           .shuffle(len(X_train))\n",
    "           .map(\n",
    "                lambda filepath,label: \n",
    "                tf.py_function(preprocess, [filepath, label],[tf.float64, tf.float64, tf.int32])\n",
    "            ).map(dict_map)\n",
    "            .batch(batch_size)\n",
    "            .prefetch(tf.data.AUTOTUNE)\n",
    "        )\n",
    "\n",
    "validation_set = (tf.data.Dataset.from_tensor_slices((X_validate,y_validate))\n",
    "           .map(\n",
    "                lambda filepath,label: \n",
    "                tf.py_function(preprocess, [filepath, label],[tf.float64, tf.float64, tf.int32])\n",
    "            ).map(dict_map)\n",
    "            .batch(10)\n",
    "            .prefetch(tf.data.AUTOTUNE)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/model_checkpoint.h5\"\n",
    "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path, \n",
    "                                      monitor='val_loss', \n",
    "                                      save_best_only=True,\n",
    "                                      save_weights_only=True,\n",
    "                                      verbose=1)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', \n",
    "                                        patience=5,\n",
    "                                        verbose=1, \n",
    "                                        restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dataset, epochs=5, batch_size=1, validation_data=validation_set,callbacks=[checkpoint_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./classifier.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
